{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blood-cells']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = '../input/blood-cells/dataset2-master/dataset2-master/images/TRAIN'\n",
    "TEST_PATH = '../input/blood-cells/null'\n",
    "\n",
    "dict_characters = {0:'EOSINOPHIL', 1:'LYMPHOCYTE', 2:'MONOCYTE', 3:'NEUTROPHIL'}\n",
    "\n",
    "\n",
    "def get_data(folder):\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for wbc_type in os.listdir(folder):\n",
    "        if not wbc_type.startswith('.'):\n",
    "            if wbc_type in ['NEUTROPHIL']:\n",
    "                label = 3\n",
    "            elif wbc_type in ['EOSINOPHIL']:\n",
    "                label = 0\n",
    "            elif wbc_type in ['MONOCYTE']:\n",
    "                label = 2  \n",
    "            elif wbc_type in ['LYMPHOCYTE']:\n",
    "                label = 1\n",
    "                \n",
    "            for image_filename in os.listdir(folder + wbc_type):\n",
    "                img_file = cv2.imread(folder + wbc_type + '/' + image_filename)\n",
    "                if img_file is not None:\n",
    "                    img_file =  cv2.resize(img_file,dsize=(80,80))\n",
    "                    img_arr = np.asarray(img_file)\n",
    "                    X.append(img_arr)\n",
    "                    y.append(label)\n",
    "    \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=get_data(\"../input/blood-cells/dataset2-master/dataset2-master/images/TRAIN/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = get_data(\"../input/blood-cells/dataset2-master/dataset2-master/images/TEST/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\", padding=\"same\",input_shape=[80, 80, 3],strides=2))\n",
    "model.add(keras.layers.MaxPooling2D(3))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(4, 4), activation=\"relu\", padding=\"same\",strides=1))\n",
    "model.add(keras.layers.MaxPooling2D(3))\n",
    "model.add(keras.layers.Conv2D(96, kernel_size=(3, 3), activation=\"relu\", padding=\"same\",strides=1))\n",
    "model.add(keras.layers.Conv2D(96, kernel_size=(2, 2), activation=\"relu\", padding=\"same\",strides=1))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(2, 2), activation=\"relu\", padding=\"same\",strides=1))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64,activation='selu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(32,activation='selu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(16,activation='selu'))\n",
    "model.add(keras.layers.Dense(4, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\", padding=\"same\",input_shape=[80, 80, 3],strides=2))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(4, 4), activation=\"relu\", padding=\"same\",strides=1))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "model.add(keras.layers.Conv2D(96, kernel_size=(3, 3), activation=\"relu\", padding=\"same\",strides=1))\n",
    "model.add(keras.layers.Conv2D(96, kernel_size=(2, 2), activation=\"relu\", padding=\"same\",strides=1))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(2, 2), activation=\"relu\", padding=\"same\",strides=1))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64,activation='selu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(32,activation='selu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(4, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer=\"adam\",\n",
    "metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=50 ,validation_split=0.2,batch_size=1000)\n",
    "plt.plot(training.history['loss'])\n",
    "plt.plot(training.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(5, 5), activation=\"selu\", padding=\"same\",input_shape=[80, 80, 3],strides=2))\n",
    "model.add(keras.layers.MaxPooling2D(3))\n",
    "model.add(keras.layers.BatchNormalization(center=True, scale=False))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(4, 4), activation=\"selu\", padding=\"same\",strides=1))\n",
    "model.add(keras.layers.MaxPooling2D(3))\n",
    "model.add(keras.layers.BatchNormalization(center=True, scale=False))\n",
    "model.add(keras.layers.Conv2D(96, kernel_size=(3, 3), activation=\"selu\", padding=\"same\",strides=1))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64,activation='selu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(32,activation='selu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(16,activation='selu'))\n",
    "model.add(keras.layers.Dense(4, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer=\"adam\",\n",
    "metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=55 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\", padding=\"same\",input_shape=[80, 80, 3],strides=2))\n",
    "model.add(keras.layers.MaxPooling2D(3))\n",
    "model.add(keras.layers.BatchNormalization(center=True, scale=False))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(4, 4), activation=\"relu\", padding=\"same\",strides=1))\n",
    "model.add(keras.layers.MaxPooling2D(3))\n",
    "model.add(keras.layers.BatchNormalization(center=True, scale=False))\n",
    "model.add(keras.layers.Conv2D(96, kernel_size=(3, 3), activation=\"relu\", padding=\"same\",strides=1))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64,activation='selu',kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(32,activation='selu',kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(16,activation='selu',kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(4, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer=\"adam\",\n",
    "metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=100 ,validation_split=0.2, batch_size=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    model5=keras.Sequential()\n",
    "    model5.add(keras.layers.Conv2D(filters=hp.Int('conv_1_filter', min_value=60, max_value=120, step=16),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [5,5]), activation=\"relu\", padding=\"valid\",input_shape=[80, 80, 3],strides=2))\n",
    "    \n",
    "    model5.add(keras.layers.MaxPooling2D(3))\n",
    "    \n",
    "    model5.add(keras.layers.BatchNormalization(center=True, scale=False))\n",
    "    \n",
    "    model5.add(keras.layers.Conv2D(filters=hp.Choice('num_filters', values=[20, 64], default=64,), \n",
    "                                   kernel_size=(4, 4), activation=\"relu\", padding=\"same\",strides=1))\n",
    "    \n",
    "    model5.add(keras.layers.MaxPooling2D(3))\n",
    "    \n",
    "    model5.add(keras.layers.BatchNormalization(center=True, scale=False))\n",
    "    \n",
    "    model5.add(keras.layers.Conv2D(96, kernel_size=(3, 3), activation=\"relu\", padding=\"same\",strides=1))\n",
    "    \n",
    "    model5.add(keras.layers.Flatten())\n",
    "    \n",
    "    hp_units = hp.Int('units', min_value = 20, max_value = 80, step = 32)\n",
    "    model5.add(keras.layers.Dense(hp_units,activation='selu',kernel_initializer=\"lecun_normal\"))\n",
    "    \n",
    "    model5.add(keras.layers.Dropout(rate=hp.Float('dropout_1', min_value=0.0,  max_value=0.4, default=0.25, step=0.05)))\n",
    "    \n",
    "    hp_units2 = hp.Int('units', min_value = 10, max_value = 30, step = 32)\n",
    "    model5.add(keras.layers.Dense(hp_units2,activation='selu',kernel_initializer=\"lecun_normal\"))\n",
    "    \n",
    "    model5.add(keras.layers.Dropout(rate=hp.Float('dropout_2', min_value=0.0,  max_value=0.4, default=0.25, step=0.05)))\n",
    "    \n",
    "    model5.add(keras.layers.Dense(16,activation='selu',kernel_initializer=\"lecun_normal\"))\n",
    "    \n",
    "    model5.add(keras.layers.Dense(4, activation=\"softmax\",kernel_initializer=\"lecun_normal\"))\n",
    "    \n",
    "    #hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "\n",
    "\n",
    "    model5.compile(optimizer = \"adam\",\n",
    "                    loss = \"sparse_categorical_crossentropy\", \n",
    "                    metrics = ['accuracy'])\n",
    "    return model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=100,\n",
    "    directory='my_dir',\n",
    "    project_name='helloworld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=10,\n",
    "             validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models3 = tuner.get_best_models(num_models=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "activation=\"selu\",\n",
    "kernel_initializer=\"lecun_normal\",\n",
    "kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=keras.Sequential()\n",
    "model1.add(keras.layers.Conv2D(108, kernel_size=(5, 5), activation=\"relu\", padding=\"same\",input_shape=[80, 80, 3],strides=2))\n",
    "model1.add(keras.layers.MaxPooling2D(3))\n",
    "model1.add(keras.layers.BatchNormalization(center=True, scale=False))\n",
    "model1.add(keras.layers.Conv2D(64, kernel_size=(4, 4), activation=\"relu\", padding=\"same\",strides=1))\n",
    "model1.add(keras.layers.MaxPooling2D(3))\n",
    "model1.add(keras.layers.BatchNormalization(center=True, scale=False))\n",
    "model1.add(keras.layers.Conv2D(96, kernel_size=(3, 3), activation=\"relu\", padding=\"same\",strides=1))\n",
    "model1.add(keras.layers.Flatten())\n",
    "model1.add(RegularizedDense(52))\n",
    "model1.add(keras.layers.Dropout(0.1))\n",
    "model1.add(RegularizedDense(52))\n",
    "model1.add(keras.layers.Dropout(0.25))\n",
    "model1.add(RegularizedDense(16))\n",
    "model1.add(keras.layers.Dense(4, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "249/249 [==============================] - 2s 10ms/step - loss: 1.9512 - accuracy: 0.5030 - val_loss: 18.1709 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "  8/249 [..............................] - ETA: 1s - loss: 1.3021 - accuracy: 0.6992"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c253a01681dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m metrics=[\"accuracy\"])\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer=\"adam\",\n",
    "metrics=[\"accuracy\"])\n",
    "model1.fit(X_train, y_train, epochs=30 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.0343 - accuracy: 0.7345 - val_loss: 12.1833 - val_accuracy: 0.2493\n",
      "Epoch 2/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.6073 - accuracy: 0.8496 - val_loss: 21.8449 - val_accuracy: 0.2493\n",
      "Epoch 3/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.4505 - accuracy: 0.8855 - val_loss: 10.0682 - val_accuracy: 0.2678\n",
      "Epoch 4/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.3393 - accuracy: 0.9171 - val_loss: 31.1903 - val_accuracy: 0.2493\n",
      "Epoch 5/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.3013 - accuracy: 0.9297 - val_loss: 3.1356 - val_accuracy: 0.4491\n",
      "Epoch 6/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.2198 - accuracy: 0.9517 - val_loss: 5.0935 - val_accuracy: 0.3715\n",
      "Epoch 7/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.1956 - accuracy: 0.9626 - val_loss: 10.9076 - val_accuracy: 0.2726\n",
      "Epoch 8/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.1809 - accuracy: 0.9680 - val_loss: 9.6698 - val_accuracy: 0.2505\n",
      "Epoch 9/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.1681 - accuracy: 0.9724 - val_loss: 2.3031 - val_accuracy: 0.6076\n",
      "Epoch 10/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.1527 - accuracy: 0.9763 - val_loss: 5.6135 - val_accuracy: 0.3764\n",
      "Epoch 11/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.1252 - accuracy: 0.9829 - val_loss: 1.1513 - val_accuracy: 0.7841\n",
      "Epoch 12/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.1215 - accuracy: 0.9827 - val_loss: 2.4790 - val_accuracy: 0.4656\n",
      "Epoch 13/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.1455 - accuracy: 0.9795 - val_loss: 2.5214 - val_accuracy: 0.5513\n",
      "Epoch 14/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.1232 - accuracy: 0.9833 - val_loss: 4.0495 - val_accuracy: 0.4254\n",
      "Epoch 15/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.0889 - accuracy: 0.9907 - val_loss: 5.2478 - val_accuracy: 0.3639\n",
      "Epoch 16/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.1227 - accuracy: 0.9831 - val_loss: 22.8827 - val_accuracy: 0.2505\n",
      "Epoch 17/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.1150 - accuracy: 0.9856 - val_loss: 1.0254 - val_accuracy: 0.8050\n",
      "Epoch 18/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.0890 - accuracy: 0.9902 - val_loss: 2.9795 - val_accuracy: 0.5629\n",
      "Epoch 19/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.1218 - accuracy: 0.9833 - val_loss: 1.1707 - val_accuracy: 0.7825\n",
      "Epoch 20/50\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.0856 - accuracy: 0.9918 - val_loss: 2.7663 - val_accuracy: 0.5155\n",
      "Epoch 21/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.0793 - accuracy: 0.9927 - val_loss: 8.7455 - val_accuracy: 0.2674\n",
      "Epoch 22/50\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.1243 - accuracy: 0.9847 - val_loss: 2.3765 - val_accuracy: 0.5907\n",
      "Epoch 23/50\n",
      "306/312 [============================>.] - ETA: 0s - loss: 0.1008 - accuracy: 0.9887"
     ]
    }
   ],
   "source": [
    "history = model1.fit(X_train, y_train,\n",
    "                    epochs = 50, validation_data =(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://keras-team.github.io/keras-tuner/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/keras/keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    model2=keras.Sequential()\n",
    "    \n",
    "    model2.add(keras.layers.Conv2D(96, kernel_size=(11, 11), activation=\"selu\", padding=\"valid\",input_shape=(240, 320, 3),strides=4))\n",
    "    model2.add(keras.layers.MaxPooling2D(3))\n",
    "    model2.add(keras.layers.Conv2D(256, kernel_size=(5, 5), activation=\"selu\", padding=\"same\",strides=1))\n",
    "    model2.add(keras.layers.MaxPooling2D(3))\n",
    "    model2.add(keras.layers.Conv2D(384, kernel_size=(3, 3), activation=\"selu\", padding=\"same\",strides=1))\n",
    "    model2.add(keras.layers.Conv2D(384, kernel_size=(3, 3), activation=\"selu\", padding=\"same\",strides=1))\n",
    "    model2.add(keras.layers.Conv2D(256, kernel_size=(3, 3), activation=\"selu\", padding=\"same\",strides=1))\n",
    "    hp_units = hp.Int('units', min_value = 16, max_value = 400, step = 16)\n",
    "    model2.add(keras.layers.Dense(units = hp_units,activation='selu'))\n",
    "    model2.add(keras.layers.Dropout(0.2))\n",
    "    hp_units2 = hp.Int(units = hp_units2, min_value = 16, max_value = 150, step = 16)\n",
    "    model2.add(keras.layers.Dense(96,activation='selu'))\n",
    "    model2.add(keras.layers.Dropout(0.2))\n",
    "    model2.add(keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    \n",
    "    # Tune the learning rate for the optimizer \n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001 (change the value according)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "    \n",
    "    \n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n",
    "                metrics = ['accuracy'])\n",
    "    \n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
